{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entities > Media Images Only\n",
    "Extraction, Download & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import shutil\n",
    "import csv\n",
    "import resource\n",
    "#import pygal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = sys.argv[1] #'/big_data/nepal/test.json'\n",
    "# image_directory = '/Users/cbopp/Data/Nepal/images/' #Include trailing slash\n",
    "output_file = sys.argv[2] #'/big_data/nepal/nepal_9-17-15.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Limit Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rsrc = resource.RLIMIT_DATA\n",
    "soft, hard = resource.getrlimit(rsrc)\n",
    "resource.setrlimit(rsrc, (2000000000, hard)) #2GB\n",
    "soft, hard = resource.getrlimit(rsrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import JSON to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file...File loaded.\n",
      "Converting to DataFrame and doing some housekeeping...Done.\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "\n",
    "print('Opening file...', end=\"\", flush=True)\n",
    "# count = 0\n",
    "for line in open(filename):\n",
    "    l.append(json.loads(line))\n",
    "#     count+=1\n",
    "#     if(count%100==0):\n",
    "#         print(count)\n",
    "print('File loaded.', flush=True)\n",
    "\n",
    "print('Converting to DataFrame and doing some housekeeping...', end=\"\", flush=True)\n",
    "df = pd.DataFrame(l)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], format=\"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "df['tweet_created_at_epoch'] = df['created_at'].astype('int64')\n",
    "df['tweet_text'] = df['text'].apply(lambda s: s.replace('\\t', '').replace('\\r', '').replace('\\n', ''))\n",
    "df['tweet_in_reply_to_user_id_str'] = df['in_reply_to_user_id_str'].apply(lambda n: str(n))\n",
    "df['tweet_in_reply_to_user_id_str'].replace('None', np.NaN, inplace=True)\n",
    "df['tweet_source'] = df['source']\n",
    "df['tweet_coords'] = df['coordinates']\n",
    "df['tweet_language'] = df['lang']\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Identify Tweets that Contain Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting media URLs...Done.\n"
     ]
    }
   ],
   "source": [
    "e_media_data = {'tweet_id_str': [], \n",
    "                'media_url': [], \n",
    "                'image_id_str': []}\n",
    "\n",
    "print('Extracting media URLs...', end=\"\", flush=True)\n",
    "for tweet in l:\n",
    "    for entity in tweet['entities']:\n",
    "        if entity == 'media':\n",
    "            for image in tweet['entities'][entity]:\n",
    "                e_media_data['tweet_id_str'].append(tweet['id_str'])\n",
    "                e_media_data['media_url'].append(image['media_url'])\n",
    "                e_media_data['image_id_str'].append(image['id_str'])\n",
    "\n",
    "e_media = pd.DataFrame(e_media_data, columns=['tweet_id_str', 'image_id_str', 'media_url'])\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('Preparing and merging DataFrames...', end=\"\", flush=True)\n",
    "#e_media['saved_to_filename'] = e_media.apply(lambda e: (e.tweet_id_str + \"-\" + e.media_url[7:]).replace(\"/\",\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "tweets_with_e_media = pd.merge(e_media, df, left_on='tweet_id_str', right_on='id_str', how='left')\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Deal with images that are gzip'ed (even though the extension is a jpg for example)\n",
    "#def download_images(row):\n",
    "\n",
    "    #url = \"http://pbs.twimg.com/media\" + urlparse(row['media_url']).path #Local\n",
    "    ##url = \"http://pbs.twimg.com\" + urlparse(row['media_url']).path #Server\n",
    "\n",
    "    #response = requests.get(url, stream=True)\n",
    "    #if response.status_code == 200:\n",
    "    #    with open(image_directory + row['saved_to_filename'], 'wb') as out_file:\n",
    "    #        shutil.copyfileobj(response.raw, out_file)\n",
    "    #    return \"1\"\n",
    "    #else:\n",
    "    #    return \"0\"\n",
    "\n",
    "#print('Downloading images...', end=\"\", flush=True)\n",
    "#tweets_with_e_media['download_status'] = tweets_with_e_media.apply(download_images, axis=1)\n",
    "#print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Merge in Other Relevant Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-8029d875cc93>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8029d875cc93>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print('Extracting retweet user info...', end=\"\", flush=True)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "user_data = {'tweet_id_str': [],\n",
    "             'user_created_at': [],\n",
    "             'user_id_str': [],\n",
    "             'user_default_avatar': [],\n",
    "             'user_followers_count': [],\n",
    "             'user_following_count': [],\n",
    "             'user_listed_count': [], \n",
    "             'user_name': [],\n",
    "             'user_screen_name': [], \n",
    "             'user_tweet_count': [], \n",
    "             'user_language': [], \n",
    "             'user_location': [],\n",
    "             'user_geo_enabled': [],\n",
    "             'user_verified': []}\n",
    "\n",
    "print('Extracting retweet user info...', end=\"\", flush=True)\n",
    "\n",
    "for tweet in l:\n",
    "    user_data['tweet_id_str'].append(tweet['id_str'])\n",
    "    user_data['user_created_at'].append(tweet['user']['created_at'])\n",
    "    user_data['user_id_str'].append(tweet['user']['id_str'])\n",
    "    user_data['user_default_avatar'].append(tweet['user']['default_profile_image'])\n",
    "    user_data['user_followers_count'].append(tweet['user']['followers_count'])\n",
    "    user_data['user_following_count'].append(tweet['user']['friends_count'])\n",
    "    user_data['user_listed_count'].append(tweet['user']['listed_count'])\n",
    "    user_data['user_name'].append(tweet['user']['name'])\n",
    "    user_data['user_screen_name'].append(tweet['user']['screen_name'])\n",
    "    user_data['user_tweet_count'].append(tweet['user']['statuses_count'])\n",
    "    user_data['user_language'].append(tweet['user']['lang'])\n",
    "    user_data['user_location'].append(tweet['user']['location'])\n",
    "    user_data['user_geo_enabled'].append(tweet['user']['geo_enabled'])\n",
    "    user_data['user_verified'].append(tweet['user']['verified'])\n",
    "        \n",
    "user = pd.DataFrame(user_data, columns=[\n",
    "        'tweet_id_str', \n",
    "        'user_created_at',\n",
    "        'user_id_str',\n",
    "        'user_default_avatar',\n",
    "        'user_followers_count',\n",
    "        'user_following_count',\n",
    "        'user_listed_count',\n",
    "        'user_name',\n",
    "        'user_screen_name',\n",
    "        'user_tweet_count',\n",
    "        'user_language',\n",
    "        'user_location',\n",
    "        'user_geo_enabled',\n",
    "        'user_verified'])\n",
    "\n",
    "user['user_created_at'] = pd.to_datetime(user['user_created_at'], format=\"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "user['user_created_at_epoch'] = user['user_created_at'].astype('int64')\n",
    "user['user_name'] = user['user_name'].apply(lambda s: s.replace('\\t', '').replace('\\r', '').replace('\\n', ''))\n",
    "\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c340a2ce364a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c340a2ce364a>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print('Extracting retweet status...', end=\"\", flush=True)\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "retweeted_status_data = {'tweet_id_str': [],\n",
    "                         'rt': [],\n",
    "                         'original_tweet_created_at': [],\n",
    "                         'original_tweet_id_str': [], \n",
    "                         'original_user_created_at': [],\n",
    "                         'original_user_id_str': [],\n",
    "                         'original_user_default_avatar': [],\n",
    "                         'original_user_followers_count': [],\n",
    "                         'original_user_following_count': [],\n",
    "                         'original_user_listed_count': [],\n",
    "                         'original_user_name': [],\n",
    "                         'original_user_screen_name': [],\n",
    "                         'original_user_tweet_count': [],\n",
    "                         'original_user_verified': [],\n",
    "                         'original_user_language': [],\n",
    "                         'original_user_location': [],\n",
    "                         'original_user_geo_enabled': [],\n",
    "                         'original_tweet_coords': [],                         \n",
    "                         'original_tweet_language': [],                         \n",
    "                         'original_tweet_text': [],                         \n",
    "                         'original_tweet_source': []}\n",
    "\n",
    "print('Extracting retweet status...', end=\"\", flush=True)\n",
    "\n",
    "for tweet in l:  \n",
    "    try:\n",
    "        tweet['retweeted_status']\n",
    "        rt = True\n",
    "    except:\n",
    "        rt = False\n",
    "        \n",
    "    if rt:\n",
    "        retweeted_status_data['tweet_id_str'].append(tweet['id_str'])\n",
    "        retweeted_status_data['rt'].append(rt)\n",
    "        retweeted_status_data['original_tweet_created_at'].append(tweet['retweeted_status']['created_at'])\n",
    "        retweeted_status_data['original_tweet_id_str'].append(tweet['retweeted_status']['id_str'])\n",
    "        retweeted_status_data['original_user_created_at'].append(tweet['retweeted_status']['user']['created_at'])\n",
    "        retweeted_status_data['original_user_id_str'].append(tweet['retweeted_status']['user']['id_str'])\n",
    "        retweeted_status_data['original_user_default_avatar'].append(tweet['retweeted_status']['user']['default_profile_image'])\n",
    "        retweeted_status_data['original_user_followers_count'].append(tweet['retweeted_status']['user']['followers_count'])\n",
    "        retweeted_status_data['original_user_following_count'].append(tweet['retweeted_status']['user']['friends_count'])\n",
    "        retweeted_status_data['original_user_listed_count'].append(tweet['retweeted_status']['user']['listed_count'])\n",
    "        retweeted_status_data['original_user_name'].append(tweet['retweeted_status']['user']['name'])\n",
    "        retweeted_status_data['original_user_screen_name'].append(tweet['retweeted_status']['user']['screen_name'])\n",
    "        retweeted_status_data['original_user_tweet_count'].append(tweet['retweeted_status']['user']['statuses_count'])\n",
    "        retweeted_status_data['original_user_verified'].append(tweet['retweeted_status']['user']['verified'])\n",
    "        retweeted_status_data['original_user_language'].append(tweet['retweeted_status']['user']['lang'])\n",
    "        retweeted_status_data['original_user_location'].append(tweet['retweeted_status']['user']['location'])\n",
    "        retweeted_status_data['original_user_geo_enabled'].append(tweet['retweeted_status']['user']['geo_enabled'])\n",
    "        retweeted_status_data['original_tweet_coords'].append(tweet['retweeted_status']['coordinates'])\n",
    "        retweeted_status_data['original_tweet_language'].append(tweet['retweeted_status']['lang'])\n",
    "        retweeted_status_data['original_tweet_text'].append(tweet['retweeted_status']['text'])\n",
    "        retweeted_status_data['original_tweet_source'].append(tweet['retweeted_status']['source'])\n",
    "    else:\n",
    "        retweeted_status_data['tweet_id_str'].append(tweet['id_str'])\n",
    "        retweeted_status_data['rt'].append(rt)\n",
    "        retweeted_status_data['original_tweet_created_at'].append(np.NaN)\n",
    "        retweeted_status_data['original_tweet_id_str'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_created_at'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_id_str'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_default_avatar'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_followers_count'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_following_count'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_listed_count'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_name'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_screen_name'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_tweet_count'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_verified'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_language'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_location'].append(np.NaN)\n",
    "        retweeted_status_data['original_user_geo_enabled'].append(np.NaN)\n",
    "        retweeted_status_data['original_tweet_coords'].append(np.NaN)\n",
    "        retweeted_status_data['original_tweet_language'].append(np.NaN)\n",
    "        retweeted_status_data['original_tweet_text'].append(np.NaN)\n",
    "        retweeted_status_data['original_tweet_source'].append(np.NaN)\n",
    "\n",
    "retweeted_status = pd.DataFrame(retweeted_status_data, columns=[\n",
    "        'tweet_id_str',\n",
    "        'rt',\n",
    "        'original_tweet_created_at', \n",
    "        'original_tweet_id_str',\n",
    "        'original_user_created_at',\n",
    "        'original_user_id_str',\n",
    "        'original_user_default_avatar',\n",
    "        'original_user_followers_count',\n",
    "        'original_user_following_count',\n",
    "        'original_user_listed_count',\n",
    "        'original_user_name',\n",
    "        'original_user_screen_name',\n",
    "        'original_user_tweet_count',\n",
    "        'original_user_verified',\n",
    "        'original_user_language',\n",
    "        'original_user_location',\n",
    "        'original_user_geo_enabled',\n",
    "        'original_tweet_coords',\n",
    "        'original_tweet_language',\n",
    "        'original_tweet_text',\n",
    "        'original_tweet_source'])\n",
    "\n",
    "retweeted_status['original_tweet_created_at'] = pd.to_datetime(retweeted_status['original_tweet_created_at'], format=\"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "retweeted_status['original_user_created_at'] = pd.to_datetime(retweeted_status['original_user_created_at'], format=\"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "retweeted_status['original_tweet_created_at_epoch'] = retweeted_status['original_tweet_created_at'].astype('int64')\n",
    "retweeted_status['original_user_created_at_epoch'] = retweeted_status['original_user_created_at'].astype('int64')\n",
    "retweeted_status['original_user_name'] = retweeted_status['original_user_name'].apply(lambda s: str(s).replace('\\t', '').replace('\\r', '').replace('\\n', ''))\n",
    "retweeted_status['original_tweet_text'] = retweeted_status['original_tweet_text'].apply(lambda s: str(s).replace('\\t', '').replace('\\r', '').replace('\\n', ''))\n",
    "\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging DataFrames...Done.\n"
     ]
    }
   ],
   "source": [
    "print('Merging DataFrames...', end=\"\", flush=True)\n",
    "tweets_with_e_media = pd.merge(tweets_with_e_media, user, left_on='tweet_id_str', right_on='tweet_id_str', how='left')\n",
    "tweets_with_e_media = pd.merge(tweets_with_e_media, retweeted_status, on='tweet_id_str', how='left')\n",
    "print('Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Binning Data/Reformatting for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source_replacements = {\n",
    "#    'web':'0',\n",
    "#    '<a href=\"http://mobile.twitter.com\" rel=\"nofollow\">Mobile Web</a>':'1',\n",
    "#    '<a href=\"http://twitter.com/devices\" rel=\"nofollow\">txt</a>':'2',\n",
    "#    '<a href=\"http://twitter.com/tweetbutton\" rel=\"nofollow\">Tweet Button</a>':'3',\n",
    "#    '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>':'4',\n",
    "#    '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>':'5',\n",
    "#    '<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for iOS</a>':'6',\n",
    "#    '<a href=\"http://www.apple.com\" rel=\"nofollow\">iOS</a>':'7',\n",
    "#    '<a href=\"http://itunes.apple.com/us/app/ap-mobile/id284901416?mt=8&uo=4\" rel=\"nofollow\">AP Mobile on iOS</a>':'8',\n",
    "#    '<a href=\"http://itunes.apple.com/us/app/twitter/id409789998?mt=12\" rel=\"nofollow\">Twitter for Mac</a>':'9',\n",
    "#    '<a href=\"http://tapbots.com/software/tweetbot/mac\" rel=\"nofollow\">Tweetbot for Mac</a>':'10',\n",
    "#    '<a href=\"http://www.apple.com\" rel=\"nofollow\">Safari on iOS</a>':'11',\n",
    "#    '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>':'12',\n",
    "#    '<a href=\"http://www.tweetcaster.com\" rel=\"nofollow\">TweetCaster for Android</a>':'13',\n",
    "#    '<a href=\"http://levelupstudio.com/plume\" rel=\"nofollow\">Plume for Android</a>':'14',\n",
    "#    '<a href=\"http://blackberry.com/twitter\" rel=\"nofollow\">Twitter for BlackBerryÂ®</a>':'15',\n",
    "#    '<a href=\"http://www.tweetdeck.com\" rel=\"nofollow\">TweetDeck</a>':'16',\n",
    "#    '<a href=\"http://www.hootsuite.com\" rel=\"nofollow\">HootSuite</a>':'17',\n",
    "#    '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>':'18',\n",
    "#    '<a href=\"http://twitterfeed.com\" rel=\"nofollow\">twitterfeed</a>':'19',\n",
    "#    '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>':'20',\n",
    "#    '<a href=\"http://www.echofon.com/\" rel=\"nofollow\">Echofon</a>':'21',\n",
    "#    '<a href=\"http://www.socialnewsdesk.com\" rel=\"nofollow\">SocialNewsDesk</a>':'22',\n",
    "#    '<a href=\"http://dlvr.it\" rel=\"nofollow\">dlvr.it</a>':'23',\n",
    "#    '<a href=\"http://twitterrific.com\" rel=\"nofollow\">Twitterrific</a>':'24'\n",
    "#}\n",
    "\n",
    "#tweets_with_e_media.replace({'source': source_replacements}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_e_media['rt'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['rt'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['user_default_avatar'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['user_default_avatar'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['user_verified'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['user_verified'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['user_geo_enabled'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['user_geo_enabled'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['original_user_default_avatar'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['original_user_default_avatar'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['original_user_verified'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['original_user_verified'].replace(False, '0', inplace=True)\n",
    "tweets_with_e_media['original_user_geo_enabled'].replace(True, '1', inplace=True)\n",
    "tweets_with_e_media['original_user_geo_enabled'].replace(False, '0', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Output to Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Remove 000000000 (trailing zeros) from all epoch times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data file...Done.\n"
     ]
    }
   ],
   "source": [
    "print('Writing data file...', end=\"\", flush=True)\n",
    "#tweets_with_e_media.to_csv(output_file, sep='\\t', na_rep='Null', columns=[\n",
    "#    'saved_to_filename', 'download_status', 'media_url', 'image_id_str', 'retweet_id_str', 'retweet_created_at_epoch', 'retweet_source', \n",
    "#    'retweet_user_id_str', 'retweet_user_default_avatar','retweet_user_followers_count', 'retweet_user_following_count', 'retweet_user_listed_count', \n",
    "#    'retweet_user_name', 'retweet_user_screen_name', 'retweet_user_tweet_count', 'retweet_user_verified', 'retweet_user_created_at_epoch',\n",
    "#    'retweet_in_reply_to_user_id_str', 'rt', \n",
    "#    'original_tweet_id_str', 'original_tweet_created_at_epoch', 'original_source', 'original_user_id_str', 'original_user_created_at_epoch', \n",
    "#    'original_user_default_avatar', 'original_user_followers_count', 'original_user_following_count', \n",
    "#    'original_user_listed_count', 'original_user_name', 'original_user_screen_name', 'original_user_tweet_count', 'original_user_verified', \n",
    "#    'retweet_text', 'original_text'], index=False)\n",
    "tweets_with_e_media.to_csv(output_file, sep='\\t', na_rep='Null', columns=[\n",
    "        'media_url', \n",
    "        'image_id_str',\n",
    "        'tweet_id_str',\n",
    "        'tweet_created_at_epoch',\n",
    "        'tweet_source',\n",
    "        'tweet_coords',\n",
    "        'tweet_language',\n",
    "        'user_id_str',\n",
    "        'user_default_avatar',\n",
    "        'user_followers_count',\n",
    "        'user_following_count',\n",
    "        'user_listed_count',\n",
    "        'user_name',\n",
    "        'user_screen_name',\n",
    "        'user_tweet_count',\n",
    "        'user_language',\n",
    "        'user_location',\n",
    "        'user_geo_enabled',\n",
    "        'user_verified',\n",
    "        'user_created_at_epoch',\n",
    "        'tweet_in_reply_to_user_id_str',\n",
    "        'rt',\n",
    "        'original_tweet_id_str',\n",
    "        'original_tweet_created_at_epoch',\n",
    "        'original_tweet_source',\n",
    "        'original_user_id_str',\n",
    "        'original_user_created_at_epoch',\n",
    "        'original_user_default_avatar',\n",
    "        'original_user_followers_count',\n",
    "        'original_user_following_count',\n",
    "        'original_user_listed_count',\n",
    "        'original_user_name',\n",
    "        'original_user_screen_name',\n",
    "        'original_user_tweet_count',\n",
    "        'original_user_verified',\n",
    "        'original_user_language',\n",
    "        'original_user_location',\n",
    "        'original_user_geo_enabled',\n",
    "        'original_tweet_coords',\n",
    "        'original_tweet_language',\n",
    "        'tweet_text',\n",
    "        'original_tweet_text'], index=False)\n",
    "print('Done.', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
